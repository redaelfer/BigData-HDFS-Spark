# Big Data Pipeline: Kafka to HDFS via Spark Streaming 

Ce projet met en place une architecture Big Data compl√®te permettant de simuler la g√©n√©ration de donn√©es, leur ingestion en temps r√©el via **Kafka**, leur traitement avec **Spark Streaming**, et enfin leur stockage persistant dans **HDFS**.

## üèóÔ∏è Architecture du Syst√®me

Le pipeline se compose des couches suivantes :

* **G√©n√©rateur (Producer)** : Un script Python qui simule l'envoi de donn√©es vers Kafka.
* **Ingestion (Kafka)** : G√®re les flux de donn√©es en temps r√©el via un broker et Zookeeper.
* **Traitement (Spark)** : Un processeur Spark Streaming qui consomme les messages Kafka et les traite.
* **Stockage (HDFS)** : Un cluster Hadoop (Namenode + Datanode) pour le stockage distribu√© des donn√©es finales.

## üõ†Ô∏è Technologies Utilis√©es

* **Apache Kafka & Zookeeper** : Ingestion et messagerie.
* **Apache Spark** : Traitement de flux (PySpark).
* **Hadoop HDFS** : Syst√®me de fichiers distribu√©.
* **Docker & Docker Compose** : Conteneurisation et orchestration.

## üöÄ Installation et Lancement

Gr√¢ce √† Docker Compose, vous pouvez lancer l'int√©gralit√© de l'infrastructure (6 services) avec une seule commande :

```bash
# Lancement de tous les services (Kafka, Spark, Hadoop, Producer)
docker-compose up --build

```

### Services d√©ploy√©s :

* **Namenode** : Port `9870` (Interface Web Hadoop).
* **Datanode** : Stockage des blocs de donn√©es.
* **Kafka Broker** : Port `9092`.
* **Zookeeper** : Port `2181`.
* **Spark Master** : Gestion du cluster Spark.
* **Producer** : Service Python automatique.

## üìÇ Structure du Repository

* `docker-compose.yml` : Orchestration de l'infrastructure compl√®te.
* `/producer` : Contient le `Dockerfile` et `main.py` pour la g√©n√©ration des donn√©es.
* `/spark` : Contient `processor.py` pour la logique de traitement en streaming.

## üìä Flux de Donn√©es

1. Le service **Producer** g√©n√®re des messages et les publie dans un topic Kafka.
2. Le **Spark Processor** lit ces messages en continu depuis Kafka.
3. Apr√®s transformation, les donn√©es sont √©crites de mani√®re distribu√©e dans le cluster **HDFS**.
